{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# VideoMagix: Multi-Template AI Content Generator\n", "\n", "This Colab notebook lets you generate content-rich videos using templates like Story, Tutorial, Poetry, Meme, Script, and more.\n", "\n", "**Features:**\n", "- Prompt to video with emotion & dialogue understanding\n", "- Image generation per scene\n", "- Voice cloning with ElevenLabs clone-compatible open-source models\n", "- Final video compilation with TTS + images + subtitles\n", "- Google Drive integration to save output\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 1: Install Dependencies\n", "!pip install transformers diffusers accelerate\n", "!pip install TTS moviepy gradio\n", "!pip install git+https://github.com/openai/whisper.git\n", "!apt-get install ffmpeg -y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 2: Mount Google Drive\n", "from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 3: Clone Required Repositories (Image Gen + Voice Cloning)\n", "!git clone https://github.com/huggingface/diffusers.git\n", "!git clone https://github.com/coqui-ai/TTS.git"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 4: Import and Setup Modules\n", "from TTS.api import TTS\n", "import torch, os\n", "from moviepy.editor import *\n", "from transformers import pipeline\n", "\n", "# Load TTS model (you can replace with another open-source voice cloning model)\n", "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5: Define Your Content Prompt\n", "Choose from the following templates: `story`, `script`, `tutorial`, `poetry`, `meme`, `video2video`, `image2video`, `clonevideo`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Example prompt\n", "prompt = \"A fantasy story about a dragon and a brave girl who saves a village.\"\n", "template = \"story\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 6: Generate Text Scenes (Simple Split for Demo)\n", "scenes = prompt.split('.')\n", "scenes = [s.strip() for s in scenes if s.strip()]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 7: Generate Images per Scene using Stable Diffusion\n", "from diffusers import StableDiffusionPipeline\n", "\n", "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n", "pipe = pipe.to(\"cuda\")\n", "\n", "image_paths = []\n", "for idx, scene in enumerate(scenes):\n", "    image = pipe(scene).images[0]\n", "    path = f\"scene_{idx}.png\"\n", "    image.save(path)\n", "    image_paths.append(path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 8: Generate Voice Audio for Each Scene\n", "audio_paths = []\n", "for idx, scene in enumerate(scenes):\n", "    audio_path = f\"scene_{idx}.wav\"\n", "    tts.tts_to_file(text=scene, file_path=audio_path)\n", "    audio_paths.append(audio_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 9: Combine Into Video\n", "clips = []\n", "for img, audio in zip(image_paths, audio_paths):\n", "    clip = ImageClip(img).set_duration(AudioFileClip(audio).duration)\n", "    clip = clip.set_audio(AudioFileClip(audio))\n", "    clips.append(clip)\n", "\n", "final_video = concatenate_videoclips(clips)\n", "output_path = \"/content/drive/MyDrive/videomagix_output.mp4\"\n", "final_video.write_videofile(output_path, fps=24)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}